{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fc0f26f4",
      "metadata": {},
      "source": [
        "# Assignment 2 specification\n",
        "\n",
        "The purpose of this assignment is to analyse the Bike Sharing Dataset hosted on the UCI repository of datasets.\n",
        "\n",
        "The dataset is provided with this notebook as a zip file.\n",
        "\n",
        "There are two related datasets in the zip file: one aggregated by day, and the other aggregated by hour.\n",
        "\n",
        "They represent the number of bikes that were shared/hired in Washington over that time period, together with the factors that are believed to predict the demand for such bikes.\n",
        "\n",
        "They include the time unit and various measures of the weather etc. (in terms of temperature, humidity and wind-speed). More description can be found [here](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset).\n",
        "\n",
        "You are asked to\n",
        "\n",
        "1. Read the _hourly_ data and split into training and test data __[5 marks]__\n",
        "2. For the _training data_ only, use exploratory data analysis to learn about the data and to indicate how to build a model __[15 marks]__\n",
        "3. Using a forward selection approach, build a regression model that offers the best performance, using a machine learning measure (i.e., prediction accuracy on the test data) __[30 marks]__\n",
        "   - You need to pay particular attention to the regression model assumptions\n",
        "   - For best performance, you will also need to perform feature engineering\n",
        "     - modifying the existing features\n",
        "     - transforming them\n",
        "     - merging them\n",
        "     - keeping feature correlation as low as possible\n",
        "   - 10-fold cross-validation should be used to estimate the uncertainty in the fitted model parameters.\n",
        "4. Identify the 3 target columns. Which of these target columns is easiest to predict accurately? __[5 marks]__\n",
        "5. Using this \"preferred target\", derive a new target whose values are the grouped label (taking the values `Q1`, `Q2`, `Q3`, `Q4`) for demand in the quartiles (0 < demand <= 25th percentile of demand), (25th percentile of demand < demand <= 50th percentile of demand), .. You might find the [pandas quantile calculator](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html) convenient when computing the quartile end points (25th, 50th and 75th percentiles), and pandas filtering by rows  convenient for assigning the new labels. __[5 marks]__\n",
        "6. Use _two_ classification procedures to predict these demand quartiles, repeating the forward selection procedure to find the best model for each, but this time focusing on classification accuracy on the test set as the measure of performance. Are the same features used in each of the two models? __[35 marks]__\n",
        "7. Which of the two machine learning procedures (regression and classification) provides the highest classification accuracy on the test set? Why is this? __[5 marks]__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2f28c2c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cda71739",
      "metadata": {},
      "source": [
        "# Task 1: Read the _hourly_ data and split into training and test data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27f45ec1",
      "metadata": {},
      "source": [
        "##Start of Answer 1##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "2b8c9125",
      "metadata": {},
      "outputs": [],
      "source": [
        "# read in the hourly data from CSV\n",
        "hourDF = pd.read_csv('data/hour.csv') \n",
        "# rename columns to be more human legible\n",
        "hourDF = hourDF.rename(columns={'instant': 'index', 'dteday': 'date', 'yr': 'year', 'mnth': 'month', 'hr': 'hour', 'weathersit': 'weather', 'temp': 'temperature', 'atemp': 'temperature-feels-like', 'hum': 'humidity','windspeed': 'wind_speed' ,'casual': 'casual_users', 'registered': 'registered_users', 'cnt': 'total_users'})\n",
        "# hourDF['season'] = hourDF['season'].astype('category')\n",
        "# hourDF['holiday'] = hourDF['holiday'].astype('category')\n",
        "# hourDF['year'] = hourDF['year'].astype('category')\n",
        "# hourDF['weekday'] = hourDF['weekday'].astype('category')\n",
        "hourDF[['season', 'holiday', 'year','weekday', 'workingday', 'weather', 'month', 'hour']] = hourDF[['season', 'holiday', 'year','weekday', 'workingday', 'weather', 'month', 'hour']].apply(lambda x: x.astype('category'))\n",
        "hourDF.to_pickle('data/hourFormatted.pk1')\n",
        "hourDF = pd.read_pickle('data/hourFormatted.pk1')\n",
        "\n",
        "#Split the Dataframe into test, training and validation data.\n",
        "trainVal, test = train_test_split(hourDF, test_size=0.2)\n",
        "train, validation = train_test_split(trainVal, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17379 entries, 0 to 17378\n",
            "Data columns (total 17 columns):\n",
            " #   Column                  Non-Null Count  Dtype   \n",
            "---  ------                  --------------  -----   \n",
            " 0   index                   17379 non-null  int64   \n",
            " 1   date                    17379 non-null  object  \n",
            " 2   season                  17379 non-null  category\n",
            " 3   year                    17379 non-null  category\n",
            " 4   month                   17379 non-null  category\n",
            " 5   hour                    17379 non-null  category\n",
            " 6   holiday                 17379 non-null  category\n",
            " 7   weekday                 17379 non-null  category\n",
            " 8   workingday              17379 non-null  category\n",
            " 9   weather                 17379 non-null  category\n",
            " 10  temperature             17379 non-null  float64 \n",
            " 11  temperature-feels-like  17379 non-null  float64 \n",
            " 12  humidity                17379 non-null  float64 \n",
            " 13  wind_speed              17379 non-null  float64 \n",
            " 14  casual_users            17379 non-null  int64   \n",
            " 15  registered_users        17379 non-null  int64   \n",
            " 16  total_users             17379 non-null  int64   \n",
            "dtypes: category(8), float64(4), int64(4), object(1)\n",
            "memory usage: 1.3+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3476 entries, 16995 to 9282\n",
            "Data columns (total 17 columns):\n",
            " #   Column                  Non-Null Count  Dtype   \n",
            "---  ------                  --------------  -----   \n",
            " 0   index                   3476 non-null   int64   \n",
            " 1   date                    3476 non-null   object  \n",
            " 2   season                  3476 non-null   category\n",
            " 3   year                    3476 non-null   category\n",
            " 4   month                   3476 non-null   category\n",
            " 5   hour                    3476 non-null   category\n",
            " 6   holiday                 3476 non-null   category\n",
            " 7   weekday                 3476 non-null   category\n",
            " 8   workingday              3476 non-null   category\n",
            " 9   weather                 3476 non-null   category\n",
            " 10  temperature             3476 non-null   float64 \n",
            " 11  temperature-feels-like  3476 non-null   float64 \n",
            " 12  humidity                3476 non-null   float64 \n",
            " 13  wind_speed              3476 non-null   float64 \n",
            " 14  casual_users            3476 non-null   int64   \n",
            " 15  registered_users        3476 non-null   int64   \n",
            " 16  total_users             3476 non-null   int64   \n",
            "dtypes: category(8), float64(4), int64(4), object(1)\n",
            "memory usage: 299.2+ KB\n",
            "\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 13903 entries, 16006 to 5952\n",
            "Data columns (total 17 columns):\n",
            " #   Column                  Non-Null Count  Dtype   \n",
            "---  ------                  --------------  -----   \n",
            " 0   index                   13903 non-null  int64   \n",
            " 1   date                    13903 non-null  object  \n",
            " 2   season                  13903 non-null  category\n",
            " 3   year                    13903 non-null  category\n",
            " 4   month                   13903 non-null  category\n",
            " 5   hour                    13903 non-null  category\n",
            " 6   holiday                 13903 non-null  category\n",
            " 7   weekday                 13903 non-null  category\n",
            " 8   workingday              13903 non-null  category\n",
            " 9   weather                 13903 non-null  category\n",
            " 10  temperature             13903 non-null  float64 \n",
            " 11  temperature-feels-like  13903 non-null  float64 \n",
            " 12  humidity                13903 non-null  float64 \n",
            " 13  wind_speed              13903 non-null  float64 \n",
            " 14  casual_users            13903 non-null  int64   \n",
            " 15  registered_users        13903 non-null  int64   \n",
            " 16  total_users             13903 non-null  int64   \n",
            "dtypes: category(8), float64(4), int64(4), object(1)\n",
            "memory usage: 1.2+ MB\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(f'{hourDF.info()}')\n",
        "print(f'\\n{test.info()}')\n",
        "print(f'\\n{trainVal.info()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57c0de73",
      "metadata": {},
      "source": [
        "##End of Answer 1##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02566724",
      "metadata": {},
      "source": [
        "# Task 2: For the training data only, use exploratory data analysis to learn about the data and to indicate how to build a model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "669d1d87",
      "metadata": {},
      "source": [
        "##Start of Answer 2##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20e92afe",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cb749cd8",
      "metadata": {},
      "source": [
        "##End of Answer 2##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5139e028",
      "metadata": {},
      "source": [
        "# Task 3: Using a forward selection approach, build a regression model that offers the best performance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830b227d",
      "metadata": {},
      "source": [
        "##Start of Answer 3##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96098d76",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "daab3816",
      "metadata": {},
      "source": [
        "##End of Answer 3##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58230825",
      "metadata": {},
      "source": [
        "# Task 4: Which of the 3 target columns is easiest to predict accurately?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fcddb07",
      "metadata": {},
      "source": [
        "##Start of Answer 4##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b217e220",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6eac9293",
      "metadata": {},
      "source": [
        "##End of Answer 4##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9e82d8d",
      "metadata": {},
      "source": [
        "# Task 5: Using this \"preferred target\", derive a new target whose values are the grouped label."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d11024e",
      "metadata": {},
      "source": [
        "##Start of Answer 5##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4db7d76",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4151956f",
      "metadata": {},
      "source": [
        "##End of Answer 5##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fec3c95",
      "metadata": {},
      "source": [
        "# Task 6: Use _two_ classification procedures to predict these demand quartiles."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6e71350",
      "metadata": {},
      "source": [
        "##Start of Answer 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b00684",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d5f36d93",
      "metadata": {},
      "source": [
        "##End of Answer 6##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a14468",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "source": [
        "# Task 7: Does regression or classification provide the best classification accuracy on the test set? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c616a7e",
      "metadata": {},
      "source": [
        "##Start of Answer 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a2aee7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "60adf3bc",
      "metadata": {},
      "source": [
        "##End of Answer 7##"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
